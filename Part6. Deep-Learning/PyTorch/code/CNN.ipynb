{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "def random_seed(seed_num):\n",
    "    torch.manual_seed(seed_num)\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "    torch.cuda.manual_seed_all(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(seed_num)\n",
    "\n",
    "random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter\n",
    "patience = 3\n",
    "verbose = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 220, 220])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "smaple = torch.randn(BATCH_SIZE, 3, 224, 224) # C, H, W\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "conv(smaple).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 분류를 위한 CNN 모델\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_ratio):\n",
    "        super(CNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),  # [BATCH_SIZE, 1, 28, 28] -> [BATCH_SIZE, 16, 24, 24]\n",
    "            nn.ReLU(),  # ReLU 활성화 함수 적용\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5), # [BATCH_SIZE, 16, 24, 24] -> [BATCH_SIZE, 32, 20, 20]\n",
    "            nn.ReLU(),  # ReLU 활성화 함수 적용\n",
    "            nn.MaxPool2d(kernel_size=2), # [BATCH_SIZE, 32, 20, 20] -> [BATCH_SIZE, 32, 10, 10]\n",
    "            nn.Dropout(dropout_ratio),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # [BATCH_SIZE, 32, 10, 10] -> [BATCH_SIZE, 64, 6, 6]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # 크기를 1/2로 줄임 [BATCH_SIZE, 64, 6, 6] -> [BATCH_SIZE, 64, 3, 3]\n",
    "            nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Linear(64*3*3, self.num_classes) # [BATCH_SIZE, 64*3*3] -> [BATCH_SIZE, num_classes]\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        Input and Output Summary\n",
    "\n",
    "        Input :\n",
    "            x : [batch_size, channel, height, width]\n",
    "        Output :\n",
    "            pred : [batch_size, num_classes]\n",
    "        '''\n",
    "        out = self.layer(x) # self.layer에 정의한 Sequential의 연산을 차례대로 다 실행 [BATCH_SIZE, 64, 3, 3]\n",
    "        out = out.view(x.size(0), -1)  # [BATCH_SIZE, 64*3*3]\n",
    "        pred = self.fc_layer(out) # [BATCH_SIZE, num_classes]\n",
    "        pred = self.softmax(pred) # [BATCH_SIZE, num_classes]\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def weight_initialization(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70282"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "dropout_ratio = 0.5\n",
    "model = CNN(num_classes = num_classes, dropout_ratio = dropout_ratio).to(device)\n",
    "model.count_parameters() # 참고로 DNN 구현(2)에 있는 모델은 약 57만개의 파라미터, 반면에 CNN은 layer 가 DNN 보다 하나 더 많음에도 불구하고, 훨씬 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor 형태로 변환\n",
    "mnist_transform = T.Compose([T.ToTensor()])# 이미지를 정규화하고 C, H, W 형식으로 바꿈\n",
    "download_root = \"../data/MNIST_DATASET\" # 경로 지정\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 48000\n",
      "Validation dataset: 12000\n"
     ]
    }
   ],
   "source": [
    "# train/val 분리\n",
    "total_size = len(train_dataset)\n",
    "train_num, valid_num = int(total_size * 0.8), int(total_size * 0.2) # 8 : 2 = train : valid\n",
    "print(f\"Train dataset: {train_num}\")\n",
    "print(f\"Validation dataset: {valid_num}\")\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num]) # train - valid set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 선언한 Dataset을 인자로 주어 DataLoader를 선언합니다.\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 코드, evaluation 코드, training_loop 코드\n",
    "def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n",
    "  model.train()  # 모델을 학습 모드로 설정\n",
    "  train_loss = 0.0\n",
    "  train_accuracy = 0\n",
    "\n",
    "  tbar = tqdm(dataloader)\n",
    "  for images, labels in tbar:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # 순전파\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # 역전파 및 가중치 업데이트\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # 손실과 정확도 계산\n",
    "      train_loss += loss.item()\n",
    "      # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      train_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "      # tqdm의 진행바에 표시될 설명 텍스트를 설정\n",
    "      tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "  # 에폭별 학습 결과 출력\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_accuracy = train_accuracy / len(train_dataset)\n",
    "\n",
    "  return model, train_loss, train_accuracy\n",
    "\n",
    "def evaluation(model, dataloader, val_dataset, criterion, device, epoch, num_epochs):\n",
    "  model.eval()  # 모델을 평가 모드로 설정\n",
    "  valid_loss = 0.0\n",
    "  valid_accuracy = 0\n",
    "\n",
    "  with torch.no_grad(): # model의 업데이트 막기\n",
    "      tbar = tqdm(dataloader)\n",
    "      for images, labels in tbar:\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          # 순전파\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          # 손실과 정확도 계산\n",
    "          valid_loss += loss.item()\n",
    "          # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          valid_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "          # tqdm의 진행바에 표시될 설명 텍스트를 설정\n",
    "          tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}\")\n",
    "\n",
    "  valid_loss = valid_loss / len(dataloader)\n",
    "  valid_accuracy = valid_accuracy / len(val_dataset)\n",
    "\n",
    "  return model, valid_loss, valid_accuracy\n",
    "\n",
    "\n",
    "def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):\n",
    "    best_valid_loss = float('inf')  # 가장 좋은 validation loss를 저장\n",
    "    early_stop_counter = 0  # 카운터\n",
    "    valid_max_accuracy = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n",
    "        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n",
    "\n",
    "        if valid_accuracy > valid_max_accuracy:\n",
    "          valid_max_accuracy = valid_accuracy\n",
    "\n",
    "        # validation loss가 감소하면 모델 저장 및 카운터 리셋\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f\"../models/model_{model_name}.pt\")\n",
    "            early_stop_counter = 0\n",
    "\n",
    "        # validation loss가 증가하거나 같으면 카운터 증가\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n",
    "\n",
    "        # 조기 종료 카운터가 설정한 patience를 초과하면 학습 종료\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    return model, valid_max_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4ee929c9994ba2a3b12ff6d4e22bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedd6aa8d2c941dc86645f9889cb6c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.1338, Train Accuracy: 0.9583 Valid Loss: 0.0620, Valid Accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6787fbf342fd46668591f693c00ea10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b7d581943a4d22b9b49df9b4a5f3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.0817, Train Accuracy: 0.9753 Valid Loss: 0.0423, Valid Accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b97b0033e64494390a268a0ee9d829d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfac9a46664940f988eadd7a91b14a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 0.0686, Train Accuracy: 0.9789 Valid Loss: 0.0354, Valid Accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f3470ed4294a0c918a5a2bbe20ebd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3e77c9373744aaa3ecec393b829746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 0.0623, Train Accuracy: 0.9809 Valid Loss: 0.0314, Valid Accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a195eb6c25473f9a8c1ac2262e92e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dc0060d68643dd8d5ee6fbed4764ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.0566, Train Accuracy: 0.9821 Valid Loss: 0.0318, Valid Accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695c7b0386a0452e8626fef1cc2ad291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808623d7550145d08f60005c9c8f07be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 0.0510, Train Accuracy: 0.9850 Valid Loss: 0.0306, Valid Accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c72e67d58b49bbac5e64295c4e8937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfc16a091824daaa506f7bd0ccdf4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 0.0492, Train Accuracy: 0.9848 Valid Loss: 0.0304, Valid Accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940d83166ab64370a3bf780f4f3e97c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacc9450ab24428cbeedf444f796d95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 0.0460, Train Accuracy: 0.9860 Valid Loss: 0.0312, Valid Accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bdc5ed457f49aca69f0d43253d7471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f800fe3689044ffb5481cf4ce9f9164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 0.0440, Train Accuracy: 0.9859 Valid Loss: 0.0266, Valid Accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e040a20ff16846ebbcf99fed360f9263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660bec271df5487f902763329c729ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0420, Train Accuracy: 0.9869 Valid Loss: 0.0281, Valid Accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00595e57ae8a442ebded6332d36513f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c6476ba76d4f75a026a06d96a7da28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 0.0402, Train Accuracy: 0.9874 Valid Loss: 0.0247, Valid Accuracy: 0.9929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5045e3c7d4bf4a8e8de2932cfed113f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbe62a2dd2a4d18801ca432fab8100d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 0.0418, Train Accuracy: 0.9874 Valid Loss: 0.0261, Valid Accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0765ca8851bc4bb9a584fea054765308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ed9f745cd040eda4e78e526bea1352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 0.0403, Train Accuracy: 0.9879 Valid Loss: 0.0256, Valid Accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a601d7ad25e4db6b6927684cd4619e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04eafbe33dcb4b2db421790165777282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Train Loss: 0.0377, Train Accuracy: 0.9879 Valid Loss: 0.0275, Valid Accuracy: 0.9911\n",
      "Early stopping\n",
      "Valid max accuracy :  0.9929166666666667\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "patience = 3\n",
    "model_name = 'cnn'\n",
    "\n",
    "lr = 1e-3\n",
    "criterion = nn.NLLLoss() # NLL loss 후 softmax 를 취하면 CrossEntropy Loss 를 취한 것과 동일하게 됨\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n",
    "print('Valid max accuracy : ', valid_max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee141717e094b67af48442d50e35746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom CNN model accuracy :  0.9937\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../models/model_cnn.pt\")) # 모델 불러오기\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "total_labels = []\n",
    "total_preds = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels\n",
    "\n",
    "        outputs = model(images)\n",
    "        # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_preds.extend(predicted.detach().cpu().tolist())\n",
    "        total_labels.extend(labels.tolist())\n",
    "\n",
    "total_preds = np.array(total_preds)\n",
    "total_labels = np.array(total_labels)\n",
    "custom_cnn_acc = accuracy_score(total_labels, total_preds) # 정확도 계산\n",
    "print(\"Custom CNN model accuracy : \", custom_cnn_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Upstage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
