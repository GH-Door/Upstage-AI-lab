{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2ab720",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4dad588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c544727",
   "metadata": {},
   "source": [
    "### 1. Tensor 이해\n",
    "\n",
    "- 1-1. Tensor 변환\n",
    "- 1-2. Tensor indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff329286",
   "metadata": {},
   "source": [
    "#### 1-1. Tensor 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57e8790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1835, 0.8359, 0.5250],\n",
       "        [0.4712, 0.8035, 0.3254]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand: 0과 1 사이의 균일한 분포에서 무작위로 생성된 Tensor 반환\n",
    "torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5620740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5660, -1.5616,  0.0110],\n",
       "        [-0.0853,  1.1672, -0.2982]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randn: 평균이 0이고 표준 편차가 1인 정규 분포(가우시안 분포)에서 무작위로 생성된 Tensor 반환\n",
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044b8b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 1, 1, 6, 1],\n",
       "        [7, 3, 3, 3, 4],\n",
       "        [9, 4, 1, 5, 9],\n",
       "        [7, 6, 4, 5, 8],\n",
       "        [1, 7, 1, 2, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randint : 주어진 범위 내에서 정수값을 무작위로 선택하여 Tensor 생성 (단, 최솟값을 포함하고, 최댓값은 포함하지 않음)\n",
    "torch.randint(1, 10, (5, 5)) # 최소값: 1, 최대값: 10, 크기: 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878dd10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 요소가 0인 Tensor 생성\n",
    "torch.zeros(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c055f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 요소가 1인 3X3 Tensor 생성\n",
    "torch.ones(2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d5de39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 5],\n",
       "        [5, 5, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full: 모든 요소가 지정된 값인 Tensor 반환\n",
    "torch.full((2, 3), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f032f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eye: 단위 행렬 반환\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f44ae",
   "metadata": {},
   "source": [
    "- Tensor 형태로 변환\n",
    "- list, tuple, numpy array 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fded6a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "tensor([1, 2, 3])\n",
      "\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list, tuple, numpy array 형태로 변환\n",
    "li = [[1, 2, 3], [4, 5, 6]]\n",
    "tu = tuple([1, 2, 3])\n",
    "np_arr = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "\n",
    "# torch.tensor(li) # 2D Tensor\n",
    "# torch.tensor(tu) # 2D Tensor\n",
    "# torch.tensor(np_arr) # 2D Tensor\n",
    "\n",
    "print(f\"{torch.tensor(li)}\\n\") # 2D Tensor\n",
    "print(f\"{torch.tensor(tu)}\\n\") # 1D Tensor\n",
    "print(f\"{torch.tensor(np_arr)}\\n\") # 3D Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bfd5c",
   "metadata": {},
   "source": [
    "- 다양한 형식의 Tensor 변환\n",
    "- as_tensor: 변환 전 데이터와 메모리 공유를 사용하므로, 변환 전 데이터 변경 시 변환되어 있는 텐서에도 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d76e3200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.tensor\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "--------------------------------------------------\n",
      "torch.as_tensor\n",
      "tensor([10,  2,  3,  4,  5])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.tensor\")\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "tensor1 = torch.tensor(data1)\n",
    "data1[0] = 10 # 0번 index 값 변경: Pandas 의 copy() 와 동일\n",
    "print(tensor1)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"torch.as_tensor\")\n",
    "data2 = np.array([1, 2, 3, 4, 5])\n",
    "tensor2 = torch.as_tensor(data2)\n",
    "data2[0] = 10 # 0번 index 값 변경: ex: df2 = df1, 즉 메모리 주소 공유\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfcea0",
   "metadata": {},
   "source": [
    "- Tensor: float32 type 으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6974a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.tensor\n",
      "Output:  tensor([1, 2, 3, 4, 5])\n",
      "Type:  torch.int64\n",
      "--------------------------------------------------\n",
      "torch.tensor\n",
      "Output:  tensor([1., 2., 3., 4., 5.])\n",
      "Type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "data = [1, 2, 3, 4, 5]\n",
    "\n",
    "tensor1 = torch.tensor(data) # tensor1 = torch.tensor(data, dtype=torch.float32) < 가능\n",
    "print(\"torch.tensor\")\n",
    "print(\"Output: \", tensor1)\n",
    "print(\"Type: \", tensor1.dtype)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "tensor2 = torch.Tensor(data) # 대문자 Tensor: flaot32 type\n",
    "print(\"torch.tensor\")\n",
    "print(\"Output: \", tensor2)\n",
    "print(\"Type: \", tensor2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0b15f",
   "metadata": {},
   "source": [
    "#### 1-2. Tensor indexing\n",
    "\n",
    "- Indexing: 텐서 내의 특정 요소를 index를 통해 접근할 수 있는 방법을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "487b668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(5)\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "# 1D Tensor indexing\n",
    "tmp_1d = torch.tensor([i for i in range(10)])\n",
    "\n",
    "print(tmp_1d[0]) # 0 번째 원소\n",
    "print(tmp_1d[5]) # 6 번째 원소\n",
    "print(tmp_1d[-1]) # 뒤에서 첫 번째 원소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "182e6fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape :  torch.Size([4, 3, 2])\n",
      "tensor([[[-0.1914,  0.3749],\n",
      "         [-1.4432,  0.5782],\n",
      "         [-1.2428,  1.2672]],\n",
      "\n",
      "        [[-0.5763,  0.0717],\n",
      "         [ 0.8030, -0.6033],\n",
      "         [-0.0178, -0.5389]],\n",
      "\n",
      "        [[ 0.0721, -0.4412],\n",
      "         [ 0.4872,  1.7534],\n",
      "         [ 1.5512, -0.5595]],\n",
      "\n",
      "        [[-0.4691,  0.1331],\n",
      "         [ 0.3724, -1.6651],\n",
      "         [-0.5307,  0.5846]]])\n",
      "--------------------------------------------------------\n",
      "torch.Size([4, 3])\n",
      "tensor([[-0.1914, -1.4432, -1.2428],\n",
      "        [-0.5763,  0.8030, -0.0178],\n",
      "        [ 0.0721,  0.4872,  1.5512],\n",
      "        [-0.4691,  0.3724, -0.5307]])\n",
      "\n",
      "\n",
      "torch.Size([3])\n",
      "tensor([0.3749, 0.5782, 1.2672])\n"
     ]
    }
   ],
   "source": [
    "# 3D Tensor Indexing\n",
    "tmp_3dim = torch.randn(4, 3, 2) # 4채널, 3행, 2열\n",
    "print(\"Shape : \", tmp_3dim.shape)\n",
    "print(tmp_3dim)\n",
    "\n",
    "print('-------'*8)\n",
    "\n",
    "print(tmp_3dim[:,:,0].shape)\n",
    "print(tmp_3dim[:,:,0]) # 전체 채널과 전체 행에서 0번째 열만 추출\n",
    "print('\\n') \n",
    "\n",
    "print(tmp_3dim[0,:,1].shape)\n",
    "print(tmp_3dim[0,:,1]) # 0번째 채널의 전체 행에서 1번째 열만 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a391698",
   "metadata": {},
   "source": [
    "- indexing_select: 선택한 차원에서 인덱스에 해당하는 요소만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f33caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2],\n",
       "        [10, 12]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index_select\n",
    "tmp_2d = torch.tensor([[i for i in range(10)], [i for i in range(10, 20)]])\n",
    "print(tmp_2d)\n",
    "\n",
    "select_idx = torch.tensor([0, 2]) # 선택하고자 하는 index는 Tesor 형태여야 함\n",
    "torch.index_select(tmp_2d, dim=1, index=select_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11fe318",
   "metadata": {},
   "source": [
    "- Masking 을 이용한 indexing: 조건문으로 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd733841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tmp_2d > 5\n",
    "print(mask)\n",
    "tmp_2d[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf14b837",
   "metadata": {},
   "source": [
    "- masked_select: 마스크 형태의 텐서를 입력으로 받아, 마스크가 True인 요소만 선택하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b97fa3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean type 이여야 함\n",
    "torch.masked_select(tmp_2d, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f79826",
   "metadata": {},
   "source": [
    "- take: 텐서를 1D로 펼친 후, 지정한 index의 값을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb60efc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_2dim = torch.tensor([[i for i in range(10)], [i for i in range(10, 20)]])\n",
    "print(f\"{tmp_2dim}\\n\")\n",
    "select_idx = torch.tensor([0, 8])\n",
    "torch.take(tmp_2dim, index=select_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c5035",
   "metadata": {},
   "source": [
    "- gather: 주어진 차원에서 인덱스에 해당하는 요소들을 선택해 새로운 Tensor 를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0080b89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
      "\n",
      "tensor([[0, 1],\n",
      "        [6, 8]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [16, 18]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_2dim = torch.tensor([[i for i in range(10)], [i for i in range(10, 20)]])\n",
    "print(f\"{tmp_2dim}\\n\")\n",
    "\n",
    "recon_idx = torch.tensor([[0, 1], [6, 8]])\n",
    "print(f\"{recon_idx}\")\n",
    "\n",
    "dim = 1\n",
    "torch.gather(tmp_2dim, dim=dim, index=recon_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8473f9",
   "metadata": {},
   "source": [
    "### 2. Tensor 모양 변경\n",
    "\n",
    "- 2-1. Tensor 의 shape을 변경 \n",
    "- 2-2. Tensor 의 차원 추가 및 변경\n",
    "- 2-3. 역할이 비슷한 함수들의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3d9af",
   "metadata": {},
   "source": [
    "#### 2-1. Tensor 의 shape을 변경 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f8a98",
   "metadata": {},
   "source": [
    "- size(): Tensor 모양 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae1014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: torch.Size([2, 3, 5])\n",
      "shape: torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# shape 과 동일한 기능\n",
    "a = torch.randn(2, 3, 5)\n",
    "print(f\"size: {a.size()}\")\n",
    "print(f\"shape: {a.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed141ca5",
   "metadata": {},
   "source": [
    "- reshape: 텐서의 모양을 변경하는 함수\n",
    "- 원소의 개수가 같은 경우에만 차원 변경이 가능\n",
    "- `-1` 값으로 모양을 자동 설정이 가능\n",
    "- 인자의 개수 → 차원 수 (몇 D인지)\n",
    "- 각 인자의 값 → 각 차원의 크기\n",
    "\n",
    "```\n",
    "reshape(3)       → 1D, shape: [3]  \n",
    "reshape(2, 3)    → 2D, shape: [2, 3]  \n",
    "reshape(2, 1, 3) → 3D, shape: [2, 1, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d104e37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8198,  0.0494, -1.3109, -0.1636,  1.6400],\n",
      "         [-1.3788, -0.2461, -0.5478, -0.5957, -2.0575],\n",
      "         [-2.3355,  2.4780,  0.9869, -1.5096,  0.8367]],\n",
      "\n",
      "        [[ 0.0483,  1.3701,  0.4443, -0.9005,  1.2575],\n",
      "         [-0.7565,  0.0971,  1.6997,  1.4092,  1.1849],\n",
      "         [ 0.2539,  0.0479, -0.7888, -0.3168, -0.1271]]])\n",
      "Shapetorch.Size([2, 3, 5])\n",
      "\n",
      "tensor([[ 0.8198,  0.0494, -1.3109, -0.1636,  1.6400, -1.3788],\n",
      "        [-0.2461, -0.5478, -0.5957, -2.0575, -2.3355,  2.4780],\n",
      "        [ 0.9869, -1.5096,  0.8367,  0.0483,  1.3701,  0.4443],\n",
      "        [-0.9005,  1.2575, -0.7565,  0.0971,  1.6997,  1.4092],\n",
      "        [ 1.1849,  0.2539,  0.0479, -0.7888, -0.3168, -0.1271]])\n",
      "Reshape: torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3, 5) # 총 원소 개수: 2 × 3 × 5 = 30\n",
    "print(a)\n",
    "print(f\"Shape{a.size()}\\n\")\n",
    "\n",
    "reshape_a = a.reshape(5, 6) # 5 × 6 = 30 → 가능\n",
    "print(reshape_a)\n",
    "print(f\"Reshape: {reshape_a.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "110958bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape A: torch.Size([3, 10])\n",
      "Reshape B: torch.Size([6, 5])\n"
     ]
    }
   ],
   "source": [
    "# -1로 모양 자동 변경\n",
    "reshape_auto_a = a.reshape(3, -1) # 앞 원소를 지정\n",
    "print(f\"Reshape A: {reshape_auto_a.size()}\")\n",
    "\n",
    "reshape_auto_b = a.reshape(-1, 5) # 뒤 원소를 지정\n",
    "print(f\"Reshape B: {reshape_auto_b.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b496b0f9",
   "metadata": {},
   "source": [
    "- reshape(4, -1) 같은 경우, 전체 원소 수가 4로 나누어떨어지지 않으면 Error 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93e30120",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, -1]' is invalid for input of size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reshape_auto_c \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 앞 원소를 지정\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape C: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreshape_auto_c\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, -1]' is invalid for input of size 30"
     ]
    }
   ],
   "source": [
    "reshape_auto_c = a.reshape(4, -1) # 앞 원소를 지정\n",
    "print(f\"Reshape C: {reshape_auto_c.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199d745",
   "metadata": {},
   "source": [
    "- view: Tensor 의 모양을 변경하는 함수\n",
    "- reshape 과 동일한 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e784ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View A: torch.Size([3, 10])\n",
      "View B: torch.Size([6, 5])\n"
     ]
    }
   ],
   "source": [
    "view_auto_a = a.view(3, -1) # 앞 원소를 지정\n",
    "print(f\"View A: {view_auto_a.size()}\")\n",
    "\n",
    "view_auto_b = a.view(-1, 5) # 뒤 원소를 지정\n",
    "print(f\"View B: {view_auto_b.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e56423",
   "metadata": {},
   "source": [
    "- transpose: Tensor 의 차원을 변경하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5d1f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4, 8, 1, 5, 2],\n",
      "         [7, 4, 6, 2, 7]],\n",
      "\n",
      "        [[3, 4, 5, 2, 6],\n",
      "         [2, 8, 9, 2, 3]],\n",
      "\n",
      "        [[9, 7, 1, 8, 5],\n",
      "         [4, 1, 1, 1, 9]]])\n",
      "Shape: torch.Size([3, 2, 5])\n",
      "\n",
      "tensor([[[4, 7],\n",
      "         [8, 4],\n",
      "         [1, 6],\n",
      "         [5, 2],\n",
      "         [2, 7]],\n",
      "\n",
      "        [[3, 2],\n",
      "         [4, 8],\n",
      "         [5, 9],\n",
      "         [2, 2],\n",
      "         [6, 3]],\n",
      "\n",
      "        [[9, 4],\n",
      "         [7, 1],\n",
      "         [1, 1],\n",
      "         [8, 1],\n",
      "         [5, 9]]])\n",
      "Shape: torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randint(1, 10, (3, 2, 5))\n",
    "print(tensor_a)\n",
    "print(f\"Shape: {tensor_a.size()}\\n\")\n",
    "\n",
    "tensor_a = tensor_a.transpose(1, 2) # 위 (3, 2, 5) → (3, 5, 2) 로 변경\n",
    "print(tensor_a)\n",
    "print(f\"Shape: {tensor_a.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f008099b",
   "metadata": {},
   "source": [
    "- permute: 차원 순서를 변경하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4341dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4, 7],\n",
      "         [8, 4],\n",
      "         [1, 6],\n",
      "         [5, 2],\n",
      "         [2, 7]],\n",
      "\n",
      "        [[3, 2],\n",
      "         [4, 8],\n",
      "         [5, 9],\n",
      "         [2, 2],\n",
      "         [6, 3]],\n",
      "\n",
      "        [[9, 4],\n",
      "         [7, 1],\n",
      "         [1, 1],\n",
      "         [8, 1],\n",
      "         [5, 9]]])\n",
      "Shape :  torch.Size([3, 5, 2])\n",
      "\n",
      "\n",
      "tensor([[[4, 8, 1, 5, 2],\n",
      "         [7, 4, 6, 2, 7]],\n",
      "\n",
      "        [[3, 4, 5, 2, 6],\n",
      "         [2, 8, 9, 2, 3]],\n",
      "\n",
      "        [[9, 7, 1, 8, 5],\n",
      "         [4, 1, 1, 1, 9]]])\n",
      "Shape :  torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a)\n",
    "print(\"Shape : \", tensor_a.size())\n",
    "print('\\n')\n",
    "\n",
    "permute_a = tensor_a.permute(0, 2, 1) # (3,2,5)의 모양을 (3,5,2)의 모양으로 변경\n",
    "print(permute_a)\n",
    "print(\"Shape : \", permute_a.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399a3ef",
   "metadata": {},
   "source": [
    "#### 2-2. Tensor 의 차원 추가 및 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994534a0",
   "metadata": {},
   "source": [
    "- unsqueeze: Tensor 에 특정 차원에 크기가 1인 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83dde254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "Shape: torch.Size([5, 2])\n",
      "\n",
      "tensor([[[0, 1],\n",
      "         [2, 3],\n",
      "         [4, 5],\n",
      "         [6, 7],\n",
      "         [8, 9]]])\n",
      "Shape: torch.Size([1, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.tensor([i for i in range(10)]).reshape(5, 2) # 2D Tensor 변환\n",
    "print(tensor_a)\n",
    "print(f\"Shape: {tensor_a.size()}\\n\")\n",
    "\n",
    "unsqu_a = tensor_a.unsqueeze(0) # 0번째 차원에 차원 추가 > (5, 2) → (1, 5, 2)\n",
    "print(unsqu_a)\n",
    "print(f\"Shape: {unsqu_a.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85f15f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0],\n",
      "         [1]],\n",
      "\n",
      "        [[2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5]],\n",
      "\n",
      "        [[6],\n",
      "         [7]],\n",
      "\n",
      "        [[8],\n",
      "         [9]]])\n",
      "Shape: torch.Size([5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "unsqu_b = tensor_a.unsqueeze(-1) # 마지막 차원에 차원 추가 > (5, 2) → (5, 2, 1)\n",
    "print(unsqu_b)\n",
    "print(f\"Shape: {unsqu_b.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713d91f",
   "metadata": {},
   "source": [
    "- squeeze: 텐서의 차원을 줄이는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a62171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [2, 3],\n",
      "         [4, 5],\n",
      "         [6, 7],\n",
      "         [8, 9]]])\n",
      "Shape :  torch.Size([1, 5, 2])\n",
      "\n",
      "\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "Shape :  torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(unsqu_a)\n",
    "print(\"Shape : \", unsqu_a.size())\n",
    "print('\\n')\n",
    "\n",
    "squ = unsqu_a.squeeze() # 차원이 1인 차원을 제거\n",
    "print(squ)\n",
    "print(\"Shape : \", squ.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75efbff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (original) :  torch.Size([2, 1, 2, 1, 2])\n",
      "\n",
      "\n",
      "Shape (squeeze()) : torch.Size([2, 2, 2])\n",
      "\n",
      "\n",
      "Shape (squeeze(0)) : torch.Size([2, 1, 2, 1, 2])\n",
      "\n",
      "\n",
      "Shape (squeeze(1)) : torch.Size([2, 2, 1, 2])\n",
      "\n",
      "\n",
      "Shape (squeeze(0,1,3)) : torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2) # 모든 원소가 0인 (2,1,2,1,2) 크기를 가지는 텐서\n",
    "print(\"Shape (original) : \", x.size()) # 원래 텐서 크기\n",
    "print('\\n')\n",
    "\n",
    "print(\"Shape (squeeze()) :\", x.squeeze().size()) # 차원이 1인 차원이 여러개일 때, 모든 차원이 1인 차원 제거\n",
    "print('\\n')\n",
    "\n",
    "print(\"Shape (squeeze(0)) :\", x.squeeze(0).size()) # 0번째 차원은 차원의 크기가 1이 아니므로, 변화 없음\n",
    "print('\\n')\n",
    "\n",
    "print(\"Shape (squeeze(1)) :\", x.squeeze(1).size()) # 1번째 차원은 차원의 크기가 1이므로 제거\n",
    "print('\\n')\n",
    "\n",
    "print(\"Shape (squeeze(0,1,3)) :\", x.squeeze((0, 1, 3)).size()) # 여러 차원 제거 가능 (0번째 차원은 차원의 크기가 1이 아니기 때문에 무시)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811cc3f",
   "metadata": {},
   "source": [
    "- expand: Tensor 의 값을 메모리에 복제하지 않고 1인 차원을 원하는 크기만큼 늘려서 “그렇게 보이게” 만드는 함수\n",
    "- `expand()` 는 1인 차원만 확장 가능\n",
    "- `expand()` 는 차원 수는 유지하면서 shape만 늘려서 구조를 바꾸는 것”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e9d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "Shape: torch.Size([4])\n",
      "\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [1, 2, 3, 4],\n",
      "        [1, 2, 3, 4]])\n",
      "Shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_1dim = torch.tensor([1, 2, 3, 4])\n",
    "print(tensor_1dim)\n",
    "print(f\"Shape: {tensor_1dim.size()}\\n\")\n",
    "\n",
    "expand_tensor = tensor_1dim.expand(3, 4) # (,4) 를 (3,4) 의 크기로 확장 (값을 반복)\n",
    "print(expand_tensor)\n",
    "print(f\"Shape: {expand_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36ebffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [1, 2, 3, 4]])\n",
      "Shape: torch.Size([2, 4])\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [4, 4].  Tensor sizes: [2, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_2dim\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m expand_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_2dim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (2,4) 를 (4,8) 의 크기로 확장 (값을 반복)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(expand_tensor) \u001b[38;5;66;03m# 에러 발생\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape : \u001b[39m\u001b[38;5;124m\"\u001b[39m, expand_tensor\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;66;03m# 에러 발생\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [4, 4].  Tensor sizes: [2, 4]"
     ]
    }
   ],
   "source": [
    "tensor_2dim = torch.tensor([[1, 2, 3, 4], [1, 2, 3, 4]]) # (2,4) 크기를 가진 Tensor\n",
    "print(tensor_2dim)\n",
    "print(f\"Shape: {tensor_2dim.size()}\\n\")\n",
    "print('\\n')\n",
    "\n",
    "expand_tensor = tensor_2dim.expand(4,4) # (2,4) 를 (4,8) 의 크기로 확장 (값을 반복)\n",
    "print(expand_tensor) # 에러 발생\n",
    "print(\"Shape : \", expand_tensor.size()) # 에러 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d15140",
   "metadata": {},
   "source": [
    "- repeat: Tensor 의 값을 반복하여 크기 확장\n",
    "- repeat()는 실제 값을 복사, 반복해서 데이터 수를 늘림\n",
    "- 정말 값을 복제해야 하거나, shape 제한이 걸릴 때 → `repeat()` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd5f04a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "Shape: torch.Size([4])\n",
      "\n",
      "tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
      "        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
      "        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]])\n",
      "repeat Shape: torch.Size([3, 16])\n",
      "\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [1, 2, 3, 4],\n",
      "        [1, 2, 3, 4]])\n",
      "expand Shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_1dim = torch.tensor([1, 2, 3, 4])\n",
    "print(tensor_1dim)\n",
    "print(f\"Shape: {tensor_1dim.size()}\\n\")\n",
    "\n",
    "repeat_tensor = tensor_1dim.repeat(3, 4) # (4,) 를 (3,4) 의 크기로 반복\n",
    "print(repeat_tensor)\n",
    "print(f\"repeat Shape: {repeat_tensor.size()}\\n\")\n",
    "\n",
    "expand_tensor = tensor_1dim.expand(3, 4) # (,4) 를 (3,4) 의 크기로 확장 (값을 반복)\n",
    "print(expand_tensor)\n",
    "print(f\"expand Shape: {expand_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7104b",
   "metadata": {},
   "source": [
    "Flatten이란?\n",
    "\n",
    "- CNN 출력 텐서 `(batch_size, channels, height, width)` → FC 레이어 입력을 위해 2D로 변환 필요\n",
    "- `flatten(start_dim=1)` 사용 → `channels × height × width`를 한 줄로 펼쳐 `(batch_size, features)` 형태로 변환\n",
    "- FC 레이어는 `(batch_size, features)` 형태의 2D만 입력 가능\n",
    "\n",
    "- ex  \n",
    "`x.shape → [32, 64, 7, 7]`  \n",
    "`x.flatten(start_dim=1).shape → [32, 3136]` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d58b77",
   "metadata": {},
   "source": [
    "- flatten: 다차원 Tensor 를 줄이고 1차원으로 변환\n",
    "- 다차원 Tensor 를 1D Tensor 로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc9bb76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5],\n",
      "         [ 6,  7],\n",
      "         [ 8,  9]],\n",
      "\n",
      "        [[10, 11],\n",
      "         [12, 13],\n",
      "         [14, 15],\n",
      "         [16, 17],\n",
      "         [18, 19]]])\n",
      "Shape: torch.Size([2, 5, 2])\n",
      "\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "Shape: torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([i for i in range(20)]).reshape(2, 5, 2) # 3D Tensor\n",
    "print(t)\n",
    "print(f\"Shape: {t.size()}\\n\")\n",
    "\n",
    "flatten_tensor = t.flatten() # 1D Tensor로 변환\n",
    "print(flatten_tensor)\n",
    "print(f\"Shape: {flatten_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3791e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Dim: 1: tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
      "Start Dim 1 Shape: torch.Size([2, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatten_tensor2 = t.flatten(start_dim=1) # 2D Tensor로 변환\n",
    "print(f\"Start Dim: 1: {flatten_tensor2}\")\n",
    "print(f\"Start Dim 1 Shape: {flatten_tensor2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c609b4",
   "metadata": {},
   "source": [
    "- ravel: 다차원 Tensor를 1D Tensor로 변환 (flatten 과 동일)\n",
    "- flatten 과 달리 어떤 축을 기준으로 평탄화 하는 작업이 없음\n",
    "- ex\n",
    "`t.ravel(1)` < Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c81b107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_TensorBase.ravel() takes no arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(t\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: _TensorBase.ravel() takes no arguments (1 given)"
     ]
    }
   ],
   "source": [
    "print(t.ravel())\n",
    "print(t.ravel(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349ed3d",
   "metadata": {},
   "source": [
    "#### 2-3. 역할이 비슷한 함수들의 차이\n",
    "\n",
    "- 모양 변경: `view` Vs `reshape` VS `unsqueeze`\n",
    "- contiguous 란?\n",
    "    - Tensor 의 메모리 상에 연속적인 데이터 batch 를 갖는 것\n",
    "    - Tensor 를 처음 생성 후 정의하면 기본적으로 contiguous 하지만\n",
    "    - 이에 대해 차원의 순서를 변경하는 과정을 거치면 contiguous 하지 않음\n",
    "    - Tensor 의 contiguous 를 하기 위해선 `is_contiguous()` 사용\n",
    "    - 즉, Tensor 의 shape 과 실제 저장된 순서가 일치하면 `contiguous=True`\n",
    "        - 아니라면 `contiguous=False` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934b177",
   "metadata": {},
   "source": [
    "- view 는 contiguous 하지 않은 Tensor 에 대해서 동작하지 않음\n",
    "- reshape 은 contiguous 하지 않은 Tensor 를 contiguous 하게 만들고 크기를 변경함\n",
    "- unsqueeze 는 차원의 크기가 1인 차원을 추가하지만 차원의 크기가 1이 아니라면 차원의 모양을 변경할 수 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cb8f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m tmp_t \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# contiguous 를 False 로 만들기 위한 작업\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(tmp_t\u001b[38;5;241m.\u001b[39mis_contiguous()) \u001b[38;5;66;03m# contiguous 한지 검사\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtmp_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# view는 contiguous 하지 않은 텐서에 대해선 동작이 되지 않음\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# view vs reshape\n",
    "tmp = torch.tensor([[[0, 1], [2, 3], [4, 5]], \\\n",
    "                 [[6, 7], [8, 9], [10, 11]], \\\n",
    "                 [[12, 13], [14, 15], [16, 17]], \\\n",
    "                 [[18, 19], [20, 21], [22, 23]]])\n",
    "tmp_t = tmp.transpose(0,1) # contiguous 를 False 로 만들기 위한 작업\n",
    "print(tmp_t.is_contiguous()) # contiguous 한지 검사\n",
    "print(tmp_t.view(-1)) # view는 contiguous 하지 않은 텐서에 대해선 동작이 되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc7bf3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  6,  7, 12, 13, 18, 19,  2,  3,  8,  9, 14, 15, 20, 21,  4,  5,\n",
      "        10, 11, 16, 17, 22, 23])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "reshape_tmp = tmp_t.reshape(-1) # reshape은 contiguous 하지 않아도 동작이 됨\n",
    "print(reshape_tmp)\n",
    "print(reshape_tmp.is_contiguous()) # contiguous 하지 않았던 Tensor를 contiguous 하게 변경해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44de1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View output size :  torch.Size([2, 3, 1])\n",
      "Reshape output size :  torch.Size([2, 3, 1])\n",
      "Unsqueeze output size :  torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# (view , reshape) vs unsqueeze\n",
    "tensor_a = torch.randn(2, 3)\n",
    "# (2, 3) 의 텐서를 (2, 3, 1)의 크기로 변경\n",
    "view_tensor = tensor_a.view(2, 3, 1) # view 를 이용하여 (2,3,1) 의 크기로 변경\n",
    "reshape_tensor = tensor_a.reshape(2, 3, 1) # reshape 를 이용하여 (2,3,1) 의 크기로 변경\n",
    "unsqueeze_tensor = tensor_a.unsqueeze(-1) # unsqueeze 를 이용하여 (2,3,1) 의 크기로 변경\n",
    "\n",
    "print(\"View output size : \",view_tensor.size())\n",
    "print(\"Reshape output size : \",reshape_tensor.size())\n",
    "print(\"Unsqueeze output size : \",unsqueeze_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e40f44b",
   "metadata": {},
   "source": [
    "- 차원 변경 : transpose vs. permute\n",
    " - transpose : 두 차원에 대해서만 변경이 가능\n",
    "   - 인자가 총 2개여야함.\n",
    " - permute : 모든 차원에 대해서 변경이 가능\n",
    "   - 인자가 차원의 개수와 동일해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "505f711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose tensor shape :  torch.Size([2, 2, 3])\n",
      "Permute tensor shape :  torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randn(2, 3, 2)\n",
    "transpose_tensor = tensor_a.transpose(2, 1) # 행과 열을 전치\n",
    "permute_tensor = tensor_a.permute(0, 2, 1) # 행과 열을 바꿈.\n",
    "\n",
    "print(\"Transpose tensor shape : \", transpose_tensor.size())\n",
    "print(\"Permute tensor shape : \", permute_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03b0af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a.permute(1, 2, 0).shape)\n",
    "print(tensor_a.transpose(2, 1).transpose(0, 2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c2998",
   "metadata": {},
   "source": [
    "### 3. Tensor 합치기 및 나누기\n",
    "\n",
    "- 3-1. 여러 Tensor 를 합치는 방법\n",
    "- 3-2. 하나의 Tensor 를 여러 텐서로 나누는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec128e02",
   "metadata": {},
   "source": [
    "#### 3-1. 여러 Tensor 를 합치는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0a838",
   "metadata": {},
   "source": [
    "- cat : 주어진 차원을 따라 Tensor 들을 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7824ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A shape :  torch.Size([2, 3])\n",
      "tensor([[6, 5, 8],\n",
      "        [4, 8, 9]])\n",
      "\n",
      "\n",
      "Tensor B shape :  torch.Size([5, 3])\n",
      "tensor([[0.3165, 0.9815, 0.0851],\n",
      "        [0.7329, 0.1316, 0.2577],\n",
      "        [0.5521, 0.8987, 0.2881],\n",
      "        [0.4396, 0.1786, 0.3598],\n",
      "        [0.9799, 0.3538, 0.4739]])\n",
      "\n",
      "\n",
      "Concat Tensor A and B (by row) Shape :  torch.Size([7, 3])\n",
      "tensor([[6.0000, 5.0000, 8.0000],\n",
      "        [4.0000, 8.0000, 9.0000],\n",
      "        [0.3165, 0.9815, 0.0851],\n",
      "        [0.7329, 0.1316, 0.2577],\n",
      "        [0.5521, 0.8987, 0.2881],\n",
      "        [0.4396, 0.1786, 0.3598],\n",
      "        [0.9799, 0.3538, 0.4739]])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randint(1, 10, (2, 3)) # 1부터 9까지의 무작위 정수가 있는 (2,3) Tensor\n",
    "tensor_b = torch.rand(5, 3) # 0부터 1까지의 균등분포를 따르는 (5,3) Tensor\n",
    "\n",
    "print(\"Tensor A shape : \", tensor_a.size())\n",
    "print(tensor_a)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Tensor B shape : \", tensor_b.size())\n",
    "print(tensor_b)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "a_cat_b_row = torch.cat((tensor_a, tensor_b), dim=0) # dim = 0 (행), Tensor A 와 Tensor B 를 행 기준으로 합친다.\n",
    "print(\"Concat Tensor A and B (by row) Shape : \", a_cat_b_row.shape) # (Tensor A 행 개수 + Tensor B 행 개수, Tensor A/B 열 개수)\n",
    "print(a_cat_b_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe789a",
   "metadata": {},
   "source": [
    "- stack : 주어진 차원을 새로운 차원으로 추가하여 Tensor 들을 쌓음\n",
    "- 합쳐질 Tensor 의 크기는 모두 같아야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb74dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A shape :  torch.Size([3, 2])\n",
      "tensor([[9, 2],\n",
      "        [8, 1],\n",
      "        [7, 9]])\n",
      "\n",
      "\n",
      "Tensor B shape :  torch.Size([3, 2])\n",
      "tensor([[0.1700, 0.1688],\n",
      "        [0.9301, 0.5784],\n",
      "        [0.9493, 0.1968]])\n",
      "\n",
      "\n",
      "Stack A and B (by row):  torch.Size([2, 3, 2])\n",
      "tensor([[[9.0000, 2.0000],\n",
      "         [8.0000, 1.0000],\n",
      "         [7.0000, 9.0000]],\n",
      "\n",
      "        [[0.1700, 0.1688],\n",
      "         [0.9301, 0.5784],\n",
      "         [0.9493, 0.1968]]])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randint(1, 10, (3, 2))  # 1부터 9까지의 무작위 정수가 있는 (3,2) Tensor\n",
    "tensor_b = torch.rand(3, 2)  # 0부터 1까지의 균등분포를 따르는 (3,2) Tensor\n",
    "\n",
    "print(\"Tensor A shape : \", tensor_a.size())\n",
    "print(tensor_a)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Tensor B shape : \", tensor_b.size())\n",
    "print(tensor_b)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "stack_tensor_row = torch.stack([tensor_a, tensor_b], dim=0)  # dim = 0, 행을 기준으로 Tensor A 에 Tensor B 를 쌓기\n",
    "print(\"Stack A and B (by row): \", stack_tensor_row.size()) # (쌓은 Tensor 개수, Tensor A/B 행 개수, Tensor A/B 열 개수)\n",
    "print(stack_tensor_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26852e",
   "metadata": {},
   "source": [
    "#### 3-2. 하나의 Tensor 를 여러 텐서로 나누는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b09007",
   "metadata": {},
   "source": [
    "- chunk: 나누고자 하는 Tensor 의 개수를 지정해서 원래의 Tensor 개수 만큼 분리\n",
    "- chunk 인자: 몇 개의 Tensor 나눌지 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "980c501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :  tensor([[7, 8, 6, 6],\n",
      "        [4, 5, 1, 6],\n",
      "        [5, 1, 5, 7],\n",
      "        [5, 1, 2, 5],\n",
      "        [6, 1, 5, 2],\n",
      "        [1, 9, 4, 8]])\n",
      "\n",
      "\n",
      "3 개의 Tensor로 분리\n",
      "\n",
      "\n",
      "0 번째 Tensor \n",
      "tensor([[7, 8, 6, 6],\n",
      "        [4, 5, 1, 6]])\n",
      "0 번째 Tensor 크기 torch.Size([2, 4])\n",
      "------------------------------\n",
      "1 번째 Tensor \n",
      "tensor([[5, 1, 5, 7],\n",
      "        [5, 1, 2, 5]])\n",
      "1 번째 Tensor 크기 torch.Size([2, 4])\n",
      "------------------------------\n",
      "2 번째 Tensor \n",
      "tensor([[6, 1, 5, 2],\n",
      "        [1, 9, 4, 8]])\n",
      "2 번째 Tensor 크기 torch.Size([2, 4])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) 텐서\n",
    "print(\"Original : \", tensor_a)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "chunk_num = 3\n",
    "chunk_tensor = torch.chunk(tensor_a, chunks = chunk_num, dim=0)  # dim = 0 (행), 6개의 행이 3개로 나누어 떨어지므로 3개의 텐서로 분리\n",
    "print(f'{len(chunk_tensor)} 개의 Tensor로 분리')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for idx,a in enumerate(chunk_tensor):\n",
    "    print(f'{idx} 번째 Tensor \\n{a}')\n",
    "    print(f'{idx} 번째 Tensor 크기', a.size())\n",
    "    print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db1a31",
   "metadata": {},
   "source": [
    "- split: 입력한 크기로 여러 개의 작은 Tensor로 나눔\n",
    "- split_size_or_sections 인자\n",
    "    - split_size (int): 얼마만큼의 크기로 자를 것인지\n",
    "    - sections (list): 얼마만큼의 크기로 각각 자를 것인지 (리스트 형태로 각 텐서의 크기를 각각 지정해 줄 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "836f46d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 4, 6],\n",
      "        [9, 7, 9, 9],\n",
      "        [9, 5, 1, 8],\n",
      "        [1, 6, 7, 7],\n",
      "        [2, 7, 4, 8],\n",
      "        [9, 6, 2, 3]])\n",
      "\n",
      "\n",
      "3 개의 Tensor로 분리\n",
      "\n",
      "\n",
      "0 번째 Tensor \n",
      "tensor([[2, 2, 4, 6],\n",
      "        [9, 7, 9, 9]])\n",
      "0 번째 Tensor 크기 torch.Size([2, 4])\n",
      "------------------------------\n",
      "1 번째 Tensor \n",
      "tensor([[9, 5, 1, 8],\n",
      "        [1, 6, 7, 7]])\n",
      "1 번째 Tensor 크기 torch.Size([2, 4])\n",
      "------------------------------\n",
      "2 번째 Tensor \n",
      "tensor([[2, 7, 4, 8],\n",
      "        [9, 6, 2, 3]])\n",
      "2 번째 Tensor 크기 torch.Size([2, 4])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) 텐서\n",
    "print(tensor_a)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "split_size = 2\n",
    "split_tensor = torch.split(tensor_a , split_size_or_sections = split_size, dim=0)  # dim = 0 (행), 텐서 A 를 행의 길이가 2 (split_size)인 텐서로 나눔\n",
    "print(f'{len(split_tensor)} 개의 Tensor로 분리')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for idx,a in enumerate(split_tensor):\n",
    "    print(f'{idx} 번째 Tensor \\n{a}')\n",
    "    print(f'{idx} 번째 Tensor 크기', a.size())\n",
    "    print('---'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Upstage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
